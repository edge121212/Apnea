{
  "model_config": {
    "architecture": "HybridOSA_Model (MPCA + Transformer)",
    "input_channels": 4,
    "output_length": 1024,
    "d_model": 64,
    "n_heads": 4,
    "n_layers": 3
  },
  "training_config": {
    "batch_size": 64,
    "learning_rate": 0.001,
    "num_epochs": 30,
    "focal_gamma": 2
  },
  "final_train_loss": 0.015675951128692304,
  "final_val_loss": 0.21648325525454293,
  "best_val_loss": 0.07409734749850237,
  "timestamp": "2025-08-25T09:34:49.536004"
}